{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/michalis0/Cloud-and-Advanced-Analytics/blob/main/week_12_GPT/fine-tunning.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1 align=\"center\"> LAB - GPT</h1>\n",
        "\n",
        "<div>\n",
        "<td> \n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/2b/Logo_Universit%C3%A9_de_Lausanne.svg/2000px-Logo_Universit%C3%A9_de_Lausanne.svg.png\" style=\"padding-right:10px;width:240px;float:left\"/></td>\n",
        "<h2 style=\"white-space: nowrap\">Cloud and Advanced Analytics </h2></td>\n",
        "<hr style=\"clear:both\">\n",
        "<p style=\"font-size:0.85em; margin:2px; text-align:justify\">\n",
        "\n",
        "</div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### LINKS AND RESSOURCES\n",
        "- https://platform.openai.com/docs/guides/fine-tuning\n",
        "- https://norahsakal.com\n",
        "- https://spotintelligence.com/2023/04/21/fine-tuning-gpt-3/"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## INTRODUCTION"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A language model is a type of artificial intelligence algorithm that can generate and understand human language. It works by predicting the next word or sequence of words in a given piece of text, based on the words that have come before it.\n",
        "\n",
        "GPT-3 (Generative Pre-trained Transformer 3) is a large, powerful language model developed by OpenAI that has been trained on a massive corpus of text data. It has been trained using a transformer architecture, which is a type of neural network that is designed to handle sequential data, such as natural language.\n",
        "\n",
        "Because of its massive size and extensive training, GPT-3 is capable of performing a wide variety of language-based tasks, including text generation, text completion, translation, and more.\n",
        "\n",
        "However, GPT-3 is a general-purpose language model, which means it has been trained on a broad range of data and doesnâ€™t have specific knowledge about any particular domain or task. This is where fine-tuning comes in.\n",
        "\n",
        "By fine-tuning a GPT-3 model on a specific task or domain, you can customize it to perform better on that task, making it more accurate and effective. This is done by feeding the model with examples specific to the task, which allows it to learn the patterns and rules that are relevant to that task."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### What is fine tuning?\n",
        "Fine-tuning is a process of retraining a pre-trained model on a specific task or domain. The idea behind fine-tuning is to leverage the pre-existing knowledge of a pre-trained model and apply it to a more specific task. Fine-tuning allows you to customize a pre-trained model to your particular needs, which can improve its performance on the given task."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Outline\n",
        "1. Get OpenAI API key\n",
        "\n",
        "2. Create training data\n",
        "\n",
        "3. Check the training data\n",
        "\n",
        "4. Upload training data\n",
        "\n",
        "5. Fine-tune model\n",
        "\n",
        "6. Check fine-tune progress\n",
        "\n",
        "7. Save fine-tuned model\n",
        "\n",
        "8. Test the new model on a new prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import openai"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. OpenAI Key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "api_key =\"YOUR_OPENAI_API_KEY\"\n",
        "openai.api_key = api_key"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Create Training Data"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Make sure to end each prompt with a suffix szch as `->` and to end each completion with a suffix as well such as `.\\n`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_file = [{\n",
        "    \"prompt\": \"Prompt ->\",\n",
        "    \"completion\": \" Ideal answer.\\n\"\n",
        "},{\n",
        "    \"prompt\":\"Prompt ->\",\n",
        "    \"completion\": \" Ideal answer.\\n\"\n",
        "}]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Save dict as JSONL file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "file_name = \"training_data.jsonl\"\n",
        "\n",
        "with open(file_name, 'w') as outfile:\n",
        "    for entry in data_file:\n",
        "        json.dump(entry, outfile)\n",
        "        outfile.write('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!openai tools fine_tunes.prepare_data -f training_data.jsonl"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Upload file to your OpenAI account"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "upload_response = openai.File.create(\n",
        "  file=open(file_name, \"rb\"),\n",
        "  purpose='fine-tune'\n",
        ")\n",
        "upload_response"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save file name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "file_id = upload_response.id\n",
        "file_id"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Fine-tune a model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The default model is `Curie` which is the most powerful one. You can also use `davinci` or `babbage` which are less powerful but cheaper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model=\"davinci\"\n",
        "fine_tune_response = openai.FineTune.create(training_file=file_id, model=model)\n",
        "fine_tune_response"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Check the status of the fine-tuning process"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The fine_tune_response refers to the response object obtained after initiating the fine-tuning process. This code snippet allows you to monitor and track the progress and status of the fine-tuning job by examining the events associated with it. The fine_tune_events variable will contain the list of events retrieved."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fine_tune_events = openai.FineTune.list_events(id=fine_tune_response.id)\n",
        "fine_tune_events"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By executing this code, you can obtain the current status, configuration, and other relevant details of the fine-tuning process. The retrieve_response variable will contain the response object with the retrieved information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "retrieve_response = openai.FineTune.retrieve(id=fine_tune_response.id)\n",
        "retrieve_response"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Save the fine-tuned model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Troubleshooting fine_tuned_model as null\n",
        "\n",
        "During the fine-tuning process, the __fine_tuned_model__ key may not be immediately available in the fine_tune_response object returned by `openai.FineTune.create().`\n",
        "\n",
        "To check the status of your fine-tuning process, you can call the `openai.FineTune.retrieve()` function and pass in the __fine_tune_response.id__. This function will return a JSON object with information about the training status, such as the current epoch, the current batch, the training loss, and the validation loss.\n",
        "\n",
        "After the fine-tuning process is complete, you can check the status of all your fine-tuned models by calling openai.FineTune.list(). This will list all of your fine-tunes and their current status.\n",
        "\n",
        "Once the fine-tuning process is complete, you can retrieve the fine_tuned_model key by calling the openai.FineTune.retrieve() function again and passing in the fine_tune_response.id. This will return a JSON object with the key fine_tuned_model and the ID of the fine-tuned model that you can use for further completions."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Option 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# If fine_tune_response.fine_tuned_model != None then the key fine_tuned_model is availble from the fine_tune_response object\n",
        "if fine_tune_response.fine_tuned_model != None:\n",
        "    fine_tuned_model = fine_tune_response.fine_tuned_model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Option 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# If fine_tune_response.fine_tuned_model == None: you can get the fine_tuned_model by listing all fine-tune events\n",
        "if fine_tune_response.fine_tuned_model == None:\n",
        "    fine_tune_list = openai.FineTune.list()\n",
        "    fine_tuned_model = fine_tune_list['data'][0].fine_tuned_model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Option 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# If fine_tune_response.fine_tuned_model == None: you can get the fine_tuned_model key by retrieving the fine-tune job\n",
        "if fine_tune_response.fine_tuned_model == None:\n",
        "    fine_tuned_model = openai.FineTune.retrieve(id=fine_tune_response.id).fine_tuned_model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Test the fine-tuned model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_prompt = \"NEW PROMPT ->\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "answer = openai.Completion.create(\n",
        "  model=fine_tuned_model,\n",
        "  prompt=new_prompt,\n",
        "  max_tokens=10, # Change amount of tokens for longer completion\n",
        "  temperature=0\n",
        ")\n",
        "answer['choices'][0]['text']"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
